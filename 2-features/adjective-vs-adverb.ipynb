{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correction of confused adjectives and adverbs\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Non-native speakers often find it difficult *(or is it difficultly?)* to learn the proper usage of adverbs and adjectives in English:\n",
    "* _Do I speak English **fluent** or **fluently**?_\n",
    "* _Why do I look **nice** but talk **nicely**?_\n",
    "* _Why is it that my car both is **fast** and goes **fast**?_\n",
    "* _Why can you both **remote control** and **remotely control** something?_\n",
    "\n",
    "In this project, we will develop a simple classifier that decides whether an adjective or an adverb is needed in a certain context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we change adjectives to adverbs and vice versa?\n",
    "\n",
    "In English, adverbs are formed from adjectives by adding \"-ly\": free => free**ly**.\n",
    "\n",
    "However, there are exceptions to that:\n",
    "- _responsib**le** => responsib**ly**_\n",
    "- _angr**y** => angr**ily**_\n",
    "- _idiot**ic** => idiot**ically**_\n",
    "- _full => full**y**_\n",
    "- _ugly => in an ugly way?_\n",
    "- _**good** => **well**_\n",
    "- _**hard** => **hard**; **hardly** has a different meaning_\n",
    "- _**state-of-the-art** => **?**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import json\n",
    "import en_core_web_md\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of English adjectives: 61768\n",
      "Total number of English adverbs: 10791\n"
     ]
    }
   ],
   "source": [
    "# Read all adjectives and adverbs that are present in English Wiktionary\n",
    "# https://en.wiktionary.org/wiki/Wiktionary:Main_Page\n",
    "\n",
    "with open(\"data/adjectives.txt\", \"r\") as f:\n",
    "    ADJ = set(line.strip() for line in f.readlines())\n",
    "\n",
    "with open(\"data/adverbs.txt\", \"r\") as f:\n",
    "    ADV = set(line.strip() for line in f.readlines())\n",
    "    \n",
    "print(\"Total number of English adjectives:\", len(ADJ))\n",
    "print(\"Total number of English adverbs:\", len(ADV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn to transform adjectives to adverbs\n",
    "\n",
    "def transform_adj_to_adv(adjective):\n",
    "    \"\"\"\n",
    "    Convert an adjective to the corresponding adverb.\n",
    "    :param adjective: string (adjective)\n",
    "    :return: string (adverb) or None\n",
    "    \"\"\"\n",
    "\n",
    "    # friendly, ugly, monthly OR meaning change\n",
    "    if adjective.endswith(\"ly\") or adjective in [\"hard\", \"bare\", \"on\"]:\n",
    "        return None\n",
    "\n",
    "    # exceptions\n",
    "    elif adjective == \"good\":\n",
    "        return \"well\"\n",
    "    elif adjective in [\"whole\", \"true\"]:\n",
    "        return adjective[:-1] + \"ly\"\n",
    "\n",
    "    # responsible => responsibly\n",
    "    elif adjective.endswith(\"le\") and adjective != \"sole\":\n",
    "        adverb = adjective[:-1] + \"y\"\n",
    "    # angry => angrily\n",
    "    elif adjective.endswith(\"y\") and adjective != \"shy\":\n",
    "        adverb = adjective[:-1] + \"ily\"\n",
    "    # idiotic => idiotically\n",
    "    elif adjective.endswith(\"ic\"):\n",
    "        adverb = adjective + \"ally\"\n",
    "    # full => fully\n",
    "    elif adjective.endswith(\"ll\"):\n",
    "        adverb = adjective + \"y\"\n",
    "    # free => freely\n",
    "    else:\n",
    "        adverb = adjective + \"ly\"\n",
    "\n",
    "    # check for validity\n",
    "    return adverb if adverb in ADV else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cobaltiferous      => None\n",
      "touched            => None\n",
      "semicylindrical    => None\n",
      "carcinomatous      => None\n",
      "antigraft          => None\n",
      "autocritical       => None\n",
      "claimable          => None\n",
      "crotchless         => None\n",
      "frigid             => frigidly\n",
      "podzolic           => None\n",
      "choreographed      => None\n",
      "pandeistic         => pandeistically\n",
      "nonlaying          => None\n",
      "tubuloalveolar     => None\n",
      "shutterless        => None\n",
      "boardlike          => None\n",
      "angleless          => None\n",
      "annotinous         => None\n",
      "tarnishable        => None\n",
      "extrathoracic      => None\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    word = random.sample(ADJ, 1)[0]\n",
    "    print(\"{:18} => {}\".format(word, transform_adj_to_adv(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of adjectives that can be transformed to adverbs (and vice versa): 8463\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries for adjective-adverb transformation\n",
    "\n",
    "adj_to_adv, adv_to_adj = dict(), dict()\n",
    "\n",
    "for adj in ADJ:\n",
    "    adv = transform_adj_to_adv(adj)\n",
    "    if adv and adv != adj:\n",
    "        adj_to_adv[adj] = adv\n",
    "        adv_to_adj[adv] = adj\n",
    "\n",
    "print(\"Number of adjectives that can be transformed to adverbs (and vice versa):\",\n",
    "      len(adj_to_adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What features distinguish adjectives from adverbs?\n",
    "\n",
    "Hypotheses:\n",
    "- left and right context\n",
    "- type of relation to the head\n",
    "- dependants (if there are any)\n",
    "- the word itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded in 26 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy models\n",
    "\n",
    "start = time.time()\n",
    "nlp = en_core_web_md.load(disable=['ner'])\n",
    "print(\"Models loaded in\", round(time.time() - start), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of speech:\n",
      "She_PRP was_VBD completely_RB natural_JJ and_CC unaffected_JJ by_IN the_DT attention_NN ._.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4261698add9749c2b705a33fd9a5251a-0\" class=\"displacy\" width=\"1150\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">completely</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">natural</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">unaffected</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">by</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">attention</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4261698add9749c2b705a33fd9a5251a-0-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,112.0 150.0,112.0 150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4261698add9749c2b705a33fd9a5251a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L62,157.0 78,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4261698add9749c2b705a33fd9a5251a-0-1\" stroke-width=\"2px\" d=\"M290,167.0 C290,112.0 370.0,112.0 370.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4261698add9749c2b705a33fd9a5251a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,169.0 L282,157.0 298,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4261698add9749c2b705a33fd9a5251a-0-2\" stroke-width=\"2px\" d=\"M180,167.0 C180,57.0 375.0,57.0 375.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4261698add9749c2b705a33fd9a5251a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M375.0,169.0 L383.0,157.0 367.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4261698add9749c2b705a33fd9a5251a-0-3\" stroke-width=\"2px\" d=\"M400,167.0 C400,112.0 480.0,112.0 480.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4261698add9749c2b705a33fd9a5251a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M480.0,169.0 L488.0,157.0 472.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4261698add9749c2b705a33fd9a5251a-0-4\" stroke-width=\"2px\" d=\"M400,167.0 C400,57.0 595.0,57.0 595.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4261698add9749c2b705a33fd9a5251a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595.0,169.0 L603.0,157.0 587.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4261698add9749c2b705a33fd9a5251a-0-5\" stroke-width=\"2px\" d=\"M620,167.0 C620,112.0 700.0,112.0 700.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4261698add9749c2b705a33fd9a5251a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">agent</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700.0,169.0 L708.0,157.0 692.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4261698add9749c2b705a33fd9a5251a-0-6\" stroke-width=\"2px\" d=\"M840,167.0 C840,112.0 920.0,112.0 920.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4261698add9749c2b705a33fd9a5251a-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,169.0 L832,157.0 848,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4261698add9749c2b705a33fd9a5251a-0-7\" stroke-width=\"2px\" d=\"M730,167.0 C730,57.0 925.0,57.0 925.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4261698add9749c2b705a33fd9a5251a-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,169.0 L933.0,157.0 917.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4261698add9749c2b705a33fd9a5251a-0-8\" stroke-width=\"2px\" d=\"M180,167.0 C180,2.0 1040.0,2.0 1040.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4261698add9749c2b705a33fd9a5251a-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1040.0,169.0 L1048.0,157.0 1032.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse sentences with adjective and adverb\n",
    "\n",
    "# sentence = nlp(\"The soup smells good.\")\n",
    "# sentence = nlp(\"He smells the soup carefully.\")\n",
    "sentence = nlp(\"She was completely natural and unaffected by the attention.\")\n",
    "\n",
    "print(\"Parts of speech:\")\n",
    "print(\" \".join(\"{}_{}\".format(token.text, token.tag_) for token in sentence))\n",
    "displacy.render(sentence, style='dep', options={\"collapse_punct\": False, \"distance\": 110}, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect features\n",
    "\n",
    "def feature_extractor(sentence, ind):\n",
    "    \"\"\"\n",
    "    Collect features for the INDth token in SENTENCE.\n",
    "    \n",
    "    :param sentence: Doc, a parsed sentence\n",
    "    :param ind: the index of the token\n",
    "    :return: a feature dictionary\n",
    "    \"\"\"\n",
    "    token = sentence[ind]\n",
    "    features = dict()\n",
    "    # context\n",
    "    features[\"w-1\"] = sentence[ind-1].text if ind > 0 else \"<S>\"\n",
    "    features[\"w+1\"] = sentence[ind+1].text if ind < (len(sentence) - 1) else \"</S>\"\n",
    "    # children\n",
    "    for child in token.children:\n",
    "        features[child.dep_] = child.text\n",
    "    # if we collect features for an adjective\n",
    "    if token.tag_ == \"JJ\" and token.text in adj_to_adv:\n",
    "        features[\"adj\"] = token.text\n",
    "        features[\"adv\"] = adj_to_adv[token.text]\n",
    "        features[\"adj_head\"] = token.dep_ + \"_\" + token.head.lemma_\n",
    "        alt_sentence = nlp(\" \".join([t.text for t in sentence[:ind]]\n",
    "                                    + [features[\"adv\"]] +\n",
    "                                    [t.text for t in sentence[ind + 1:]]))\n",
    "        features[\"adv_head\"] = alt_sentence[ind].dep_ + \"_\" + \\\n",
    "                               alt_sentence[ind].head.lemma_\n",
    "    # if we collect features for an adverb\n",
    "    elif token.tag_ == \"RB\" and token.text in adv_to_adj:\n",
    "        features[\"adv\"] = token.text\n",
    "        features[\"adj\"] = adv_to_adj[token.text]\n",
    "        features[\"adv_head\"] = token.dep_ + \"_\" + token.head.lemma_\n",
    "        alt_sentence = nlp(\" \".join([t.text for t in sentence[:ind]]\n",
    "                                    + [features[\"adj\"]] +\n",
    "                                    [t.text for t in sentence[ind + 1:]]))\n",
    "        features[\"adj_head\"] = alt_sentence[ind].dep_ + \"_\" + \\\n",
    "                               alt_sentence[ind].head.lemma_\n",
    "    else:\n",
    "        # the input data may be noisy\n",
    "        return None\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word in question: good\n",
      "{'w-1': 'smells', 'w+1': '.', 'adj': 'good', 'adv': 'well', 'adj_head': 'acomp_smell', 'adv_head': 'advmod_smell'}\n",
      "Label: ADJ\n",
      "\n",
      "Word in question: carefully\n",
      "{'w-1': 'soup', 'w+1': '.', 'adv': 'carefully', 'adj': 'careful', 'adv_head': 'advmod_smell', 'adj_head': 'oprd_smell'}\n",
      "Label: ADV\n",
      "\n",
      "Word in question: natural\n",
      "{'w-1': 'completely', 'w+1': 'and', 'advmod': 'completely', 'cc': 'and', 'conj': 'unaffected', 'adj': 'natural', 'adv': 'naturally', 'adj_head': 'acomp_be', 'adv_head': 'advmod_be'}\n",
      "Label: ADJ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect features for sample sentences\n",
    "\n",
    "corpus = [\"The soup smells good.\",\n",
    "          \"He smells the soup carefully.\",\n",
    "          \"She was completely natural and unaffected by the attention.\"]\n",
    "\n",
    "data, labels = [], []\n",
    "for sentence in corpus:\n",
    "    sentence = nlp(sentence)\n",
    "    for token in sentence:\n",
    "        if token.tag_ in [\"JJ\", \"RB\"] and token.head.tag_.startswith(\"VB\"):\n",
    "            features = feature_extractor(sentence, token.i)\n",
    "            data.append(features)\n",
    "            labels.append(token.pos)\n",
    "            print(\"Word in question:\", token.text)\n",
    "            print(features)\n",
    "            print(\"Label:\", token.pos_)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize features for sample sentences\n",
    "\n",
    "vec = DictVectorizer()\n",
    "vectorized_feats = vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features:\n",
      "['adj=careful', 'adj=good', 'adj=natural', 'adj_head=acomp_be', 'adj_head=acomp_smell', 'adj_head=oprd_smell', 'adv=carefully', 'adv=naturally', 'adv=well', 'adv_head=advmod_be', 'adv_head=advmod_smell', 'advmod=completely', 'cc=and', 'conj=unaffected', 'w+1=.', 'w+1=and', 'w-1=completely', 'w-1=smells', 'w-1=soup']\n",
      "\n",
      "Total number of features:  19\n"
     ]
    }
   ],
   "source": [
    "# The full feature set\n",
    "\n",
    "print(\"All features:\")\n",
    "print(vec.get_feature_names())\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting sparse matrix:\n",
      "[[0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# The resulting sparse matrix\n",
    "\n",
    "print(\"The resulting sparse matrix:\")\n",
    "print(vectorized_feats.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do we get data?\n",
    "\n",
    "Possible sources of data are:\n",
    "- learner corpora (e.g., [lang-8](http://cl.naist.jp/nldata/lang-8/), [NUCLE](http://www.comp.nus.edu.sg/~nlp/conll14st.html))\n",
    "- use crowdsourcing platform (e.g, [MTurk](https://www.mturk.com/)) or linguists (e.g., [Appen](https://appen.com/)) to annotate data\n",
    "- use grammatically correct data\n",
    "\n",
    "Suppose we don't have any money or time (which we don't :trollface:). Thus, we will be using a corpus of allegedly correct English - [The Blog Authorship Corpus](http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': ['that', 'was', 'huge', 'and', 'really', 'pretty', '.'], 'label': 'ADJ', 'ind': 2}\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/adj_vs_adv_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20000 samples in the data set.\n",
      "10000 for ADJ and 10000 for ADV.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} samples in the data set.\".format(len(data)))\n",
    "print(\"{} for ADJ and {} for ADV.\".format(len([i for i in data if i[\"label\"] == \"ADJ\"]),\n",
    "                                          len([i for i in data if i[\"label\"] == \"ADV\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the data is already tokenized, it's better to use a custom space tokenizer\n",
    "\n",
    "class WordTokenizer(object):\n",
    "    \"\"\"\n",
    "    Custom Tokenizer\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab=nlp.vocab, tokenizer=None, return_doc=True):\n",
    "        self.vocab = vocab\n",
    "        self._word_tokenizer = tokenizer\n",
    "        self.return_doc = return_doc\n",
    "\n",
    "    def __call__(self, text):\n",
    "        if self._word_tokenizer:\n",
    "            words = self._word_tokenizer.tokenize(text)\n",
    "        else:\n",
    "            words = text.split(' ')\n",
    "        if self.return_doc:\n",
    "            spaces = [True] * len(words)\n",
    "            return Doc(self.vocab, words=words, spaces=spaces)\n",
    "        else:\n",
    "            return words\n",
    "\n",
    "nlp.tokenizer = WordTokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted in 7 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Collect features and labels from our data set\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "x, y = [], []\n",
    "for sample in data:\n",
    "    sentence = nlp(\" \".join(sample[\"sentence\"]))\n",
    "    features = feature_extractor(sentence, sample[\"ind\"])\n",
    "    if features:\n",
    "        x.append(features)\n",
    "        y.append(sample[\"label\"])\n",
    "\n",
    "print(\"Features extracted in\", round((time.time() - start) / 60), \"minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of ADJ to ADV in the train data is 1.0.\n",
      "The ratio of ADJ to ADV in the test data is 0.97.\n"
     ]
    }
   ],
   "source": [
    "# Check the balance\n",
    "\n",
    "train_adj = len([i for i in y_train if i == \"ADJ\"])\n",
    "test_adj = len([i for i in y_test if i == \"ADJ\"])\n",
    "print(\"The ratio of ADJ to ADV in the train data is {}.\".format(round(train_adj / (len(y_train) - train_adj), 2)))\n",
    "print(\"The ratio of ADJ to ADV in the test data is {}.\".format(round(test_adj / (len(y_test) - test_adj), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  13685\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "x_train_vect = vectorizer.fit_transform(x_train)\n",
    "print(\"\\nTotal number of features: \", len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=500, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a classifier\n",
    "\n",
    "lrc = LogisticRegression(random_state=42, max_iter=500, solver='saga')\n",
    "lrc.fit(x_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.96      0.95      0.95      1968\n",
      "         ADV       0.95      0.96      0.95      2019\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3987\n",
      "   macro avg       0.95      0.95      0.95      3987\n",
      "weighted avg       0.95      0.95      0.95      3987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = lrc.predict(vectorizer.transform(x_test))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the classifier to detect incorrect usage of adjectives with verbs\n",
    "\n",
    "def is_adj_correct(raw_sentence):\n",
    "    sentence = nlp(raw_sentence)\n",
    "    print(\"Input:\", raw_sentence)\n",
    "    for ind in range(len(sentence)):\n",
    "        token = sentence[ind]\n",
    "        if token.tag_ == \"JJ\" and token.head.tag_.startswith(\"VB\"):\n",
    "            features = feature_extractor(sentence, ind)\n",
    "            if not features:\n",
    "                print(\"No errors found.\")\n",
    "                return\n",
    "            predicted_pos = lrc.predict(vectorizer.transform(features))\n",
    "            if predicted_pos == \"ADJ\":\n",
    "                print(\"No errors found.\")\n",
    "                return\n",
    "            else:\n",
    "                print(\" \".join([t.text for t in sentence[:ind]]\n",
    "                                + [\"{\" + sentence[ind].text + \"=>\" + adj_to_adv[sentence[ind].text] + \"}\"] +\n",
    "                                [t.text for t in sentence[ind+1:]]))\n",
    "                return\n",
    "    print(\"No errors found.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: You talk nice .\n",
      "You talk {nice=>nicely} .\n",
      "\n",
      "Input: You look nice .\n",
      "No errors found.\n",
      "\n",
      "Input: You speak fluent .\n",
      "You speak {fluent=>fluently} .\n",
      "\n",
      "Input: I do n't want TeamViewer to remote control my computer .\n",
      "I do n't want TeamViewer to {remote=>remotely} control my computer .\n",
      "\n",
      "Input: You have successful completed the project .\n",
      "You have {successful=>successfully} completed the project .\n",
      "\n",
      "Input: I am busy talking to my friend .\n",
      "No errors found.\n",
      "\n",
      "Input: I am emotional talking to my friend .\n",
      "I am {emotional=>emotionally} talking to my friend .\n",
      "\n",
      "Input: The soup smells good .\n",
      "No errors found.\n",
      "\n",
      "Input: He smells the soup careful .\n",
      "He smells the soup {careful=>carefully} .\n",
      "\n",
      "Input: She was completely natural and unaffected by the attention .\n",
      "No errors found.\n",
      "\n",
      "Input: She was complete natural and unaffected by the attention .\n",
      "She was {complete=>completely} natural and unaffected by the attention .\n"
     ]
    }
   ],
   "source": [
    "is_adj_correct(\"You talk nice .\")\n",
    "print()\n",
    "is_adj_correct(\"You look nice .\")\n",
    "print()\n",
    "is_adj_correct(\"You speak fluent .\")\n",
    "print()\n",
    "is_adj_correct(\"I do n't want TeamViewer to remote control my computer .\")\n",
    "print()\n",
    "is_adj_correct(\"You have successful completed the project .\")\n",
    "print()\n",
    "is_adj_correct(\"I am busy talking to my friend .\")\n",
    "print()\n",
    "is_adj_correct(\"I am emotional talking to my friend .\")\n",
    "print()\n",
    "is_adj_correct(\"The soup smells good .\")\n",
    "print()\n",
    "is_adj_correct(\"He smells the soup careful .\")\n",
    "print()\n",
    "is_adj_correct(\"She was completely natural and unaffected by the attention .\")\n",
    "print()\n",
    "is_adj_correct(\"She was complete natural and unaffected by the attention .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features that correlate with ADJ:\n",
      "det=the adv_head=acomp_be prep=about nsubj=it adj_head=acomp_become w+1=! prep=with adj_head=acomp_be adj_head=oprd_keep adj_head=oprd_seem prep=in w+1=or prep=of punct=, prep=to prep=for w-1=The adj_head=ccomp_make w+1=to w+1=as adj_head=amod_look w+1=and adj_head=acomp_sound prep=at w-1=make\n",
      "\n",
      "Features that correlate with ADV:\n",
      "adj=actual adv=actually adj=probable adv=probably adj=real adv=really adv=finally adj=final w+1=a adj=definite adv=definitely adv=especially adj=especial adv=currently adj=current w-1=I adj=exact adv=exactly adj=recent adv=recently adj=basic adv=basically adv=certifiably adj=certifiable adv=slightly\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "top_features = np.argsort(lrc.coef_[0])\n",
    "\n",
    "print(\"Features that correlate with ADJ:\")\n",
    "print(\" \".join(feature_names[i] for i in top_features[:25]))\n",
    "print()\n",
    "\n",
    "print(\"Features that correlate with ADV:\")\n",
    "print(\" \".join(feature_names[i] for i in top_features[::-1][:25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "* Split the data into train/dev/test and analyze the examples where the classifier fails. Could you add or change features to improve the quality?\n",
    "* Add a function to correct adverbs to adjectives.\n",
    "* Experiment with other classifiers and parameters.\n",
    "* Check if using a larger spaCy model (en_core_web_lg) improves the parse quality and the quality of the classifier.\n",
    "* Test the solution on a corpus of correct texts to measure the FP rate.\n",
    "* Test the classifier on one of the available error correction corpora (e.g., NUCLE) to measure precision and recall.\n",
    "* Tweak the [data extraction script](aux/prepare_data.py) to collect adjectives and adverbs in other syntactic contexts and build a better solution. Note the size and balance of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
